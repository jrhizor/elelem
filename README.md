# Elelem
Elelem is a simple, opinionated, JSON-typed, and traced LLM framework in TypeScript.

[//]: # (todo video)

## Why another LLM library?

I recently tried to port [MealByMeal](https://mealbymeal.app/), a production LLM-based application, over to LangChain. 
The journey was not without its challenges. 
For starters, caching is currently unsupported for chat-based endpoints, specifically for `gpt-3.5-turbo`. 
Additionally, the interface for interacting with these endpoints felt quite awkward. 
Continuously handling and enforcing typed outputs turned out to be both repetitive and error-prone. 
Furthermore, without leveraging `gpt-4`, the structured outputs were seldom valid. 
As for debugging nuances like retries and parsing errors, the in-built tracing leaves much to be desired.
All of these issues led me to create my own lightweight library.

## How does Elelem compare to LangChain?

| Feature                                    | Elelem | Langchain |
|--------------------------------------------|--------|-----------|
| TypeScript library                         | ✅      | ✅         |
| Emphasis on typed LLM outputs              | ✅      | ❌         |
| Easily composable multi-step LLM workflows | ✅      | ❌         |
| Convenient API for single chat completions | ✅      | ❌         |
| Caching for OpenAI chat endpoints          | ✅      | ❌         |
| OpenTelemetry support                      | ✅      | ❌         |
| Autogenerated JSON examples in prompts     | ✅      | ❌         |
| Python library                             | ❌      | ✅         |
| Non-OpenAI model support                   | ❌      | ✅         |
| Vector store support                       | ❌      | ✅         |
| A million other features                   | ❌      | ✅         |

## Example Usage

```
yarn add elelem
```

```typescript
// todo
```

## Viewing Traces on Jaeger

Start [Jaeger](https://www.jaegertracing.io/) locally using:
```
docker run --rm --name jaeger \
  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 4317:4317 \
  -p 4318:4318 \
  -p 14250:14250 \
  -p 14268:14268 \
  -p 14269:14269 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.49
```

Allow publishing traces to Jaeger with the following:
```typescript
import * as opentelemetry from "@opentelemetry/sdk-node";
import { OTLPTraceExporter } from "@opentelemetry/exporter-trace-otlp-proto";

const sdk = new opentelemetry.NodeSDK({
    serviceName: "your-service-name",
    traceExporter: new OTLPTraceExporter(),
});
sdk.start();

// rest of your code...

process.on('SIGTERM', () => {
    sdk.shutdown()
        .then(() => console.log('Tracing terminated'))
        .catch((error) => console.log('Error terminating tracing', error))
        .finally(() => process.exit(0));
});
```

When you run your code, your traces will be available at http://localhost:16686/.

### Tracing in Production

See the [OpenTelemetry docs](https://opentelemetry.io/docs/instrumentation/js/exporters/) for more information on sending traces to hosted instances of Zipkin, Jaeger, Datadog, etc.

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.

## For Contributors: Running Integration Tests

To run tests, first make sure you have Git, Yarn, and Docker installed. Then checkout the repo and install dependencies:
```
git clone git@github.com:jrhizor/elelem.git
cd elelem
yarn install
```

Create a `.env` file:
```
OPENAI_API_KEY=<your key>
REDIS=redis://localhost:6379
```

Start up Redis:
```
docker run -it -p 6379:6379 redis
```

Start up Jaeger:
```
docker run --rm --name jaeger \
  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 4317:4317 \
  -p 4318:4318 \
  -p 14250:14250 \
  -p 14268:14268 \
  -p 14269:14269 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.49
```

Now you're ready to run the unit and integration tests:
```
yarn test
```

## License

[MIT](https://choosealicense.com/licenses/mit/)
