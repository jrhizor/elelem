# Elelem
Elelem is a simple, opinionated, JSON-typed, and traced LLM framework in TypeScript.

[//]: # (todo video)

## Why another LLM library?

I recently tried to port a [production LLM-based application](https://www.mealtext.app/) over to LangChain. 
The journey was not without its challenges. 
For starters, caching is currently unsupported for chat-based endpoints, specifically for `gpt-3.5-turbo`. 
Additionally, the interface for interacting with these endpoints felt quite awkward. 
Continuously handling and enforcing typed outputs turned out to be both repetitive and error-prone. 
Furthermore, without leveraging `gpt-4`, the structured outputs were seldom valid. 
As for debugging nuances like retries and parsing errors, the in-built tracing leaves much to be desired.
All of these issues led me to create my own lightweight library.

## How does Elelem compare to LangChain?

| Feature                                    | Elelem | Langchain |
|--------------------------------------------|--------|-----------|
| TypeScript library                         | ✅      | ✅         |
| Emphasis on typed LLM outputs              | ✅      | ❌         |
| Easily composable multi-step LLM workflows | ✅      | ❌         |
| Convenient API for single chat completions | ✅      | ❌         |
| Caching for OpenAI chat endpoints          | ✅      | ❌         |
| OpenTelemetry support                      | ✅      | ❌         |
| Autogenerated JSON examples in prompts     | ✅      | ❌         |
| Python library                             | ❌      | ✅         |
| Non-OpenAI model support                   | ❌      | ✅         |
| Vector store support                       | ❌      | ✅         |
| A million other features                   | ❌      | ✅         |

## Example Usage

```
yarn add elelem
```

```typescript
// todo
```

## Viewing Traces

[//]: # (todo code example for publishing)

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)
